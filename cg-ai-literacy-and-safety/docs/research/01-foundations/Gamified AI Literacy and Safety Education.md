# **Pedagogical Paradigms in Artificial Intelligence: A Comprehensive Analysis of Gamified Literacy, Safety Frameworks, and Applied Learning Modalities**

## **1\. Introduction: The Sociotechnical Imperative of AI Literacy**

The rapid proliferation of artificial intelligence (AI) technologies—ranging from generative Large Language Models (LLMs) to autonomous decision-making systems in finance, healthcare, and criminal justice—has precipitated a fundamental shift in the global educational landscape. We are witnessing the transition from a "digital native" generation to an "AI native" generation, where the primary competency is no longer merely operating digital tools, but understanding, collaborating with, and critically evaluating probabilistic, non-deterministic systems. This report provides an exhaustive analysis of the current state of AI literacy and safety education, with a specific focus on gamification as a transformative pedagogical modality.

### **1.1 The Definition of AI Literacy in a Generative Age**

Traditionally, computer science education prioritized syntax, logic, and deterministic programming—teaching students to write code that produces predictable outputs. However, the current technological paradigm requires a broader, "sociotechnical" definition of literacy. As identified in recent literature, AI literacy encompasses not only the technical understanding of how machine learning (ML) models function but also the capacity to evaluate their ethical implications, recognize their limitations, and interact with them safely.1

The definition of AI literacy has evolved to include four distinct interconnected domains, as outlined in the "Empowering Learners for the Age of AI" framework developed by the European Commission and the OECD. These domains—Engaging with AI, Creating with AI, Managing AI, and Designing AI—suggest that literacy is a spectrum of agency.3 At the foundational level, learners must be able to use AI tools effectively for information retrieval and recommendation. At the highest level, they must possess the design thinking skills to shape AI systems that align with human values and societal needs.

This shift is echoed in state-level guidance, such as that from the Massachusetts Department of Elementary and Secondary Education, which emphasizes the necessity of navigating "significant risks and challenges" alongside opportunities. The guidance explicitly links literacy to the ability to address concerns related to academic integrity, bias, data privacy, and misinformation.1 Similarly, the California Department of Education outlines a progression of learning goals that moves from "Notice & Name" in early childhood to "Design & Influence" in high school, where students are expected to conduct model audits and propose policy.5

### **1.2 The Pedagogical Void and the Role of Gamification**

Despite the urgency, there remains a significant gap between the complexity of AI concepts and the accessibility of traditional educational materials. AI concepts such as neural network weights, backpropagation, reinforcement learning reward functions, and high-dimensional vector spaces are abstract and often counter-intuitive. Traditional didactic methods—lectures and textbooks—struggle to convey the dynamic, emergent behavior of these systems.

Gamification—the integration of game mechanics, dynamics, and aesthetics into non-game contexts—has emerged as a critical strategy to bridge this gap. By turning the "black box" of AI into a transparent, interactive playground, gamification leverages constructivist learning theories, allowing students to build their understanding through experimentation and failure. Research indicates that game-based learning in AI can significantly enhance motivation, engagement, and the retention of complex technical concepts.6

Furthermore, gamification provides a safe environment for simulating high-stakes AI safety scenarios. In the real world, a misaligned AI system or a biased hiring algorithm can cause irreparable harm. In a gamified simulation, these failures become powerful learning moments. Students can experience the "Existential Risk" of an unchecked superintelligence or the societal friction of algorithmic segregation without real-world consequences, thereby internalizing the gravity of AI safety principles.8

## **2\. Theoretical Frameworks and Educational Strategies**

To understand how AI literacy is taught effectively, one must first examine the pedagogical frameworks that structure these interventions. Current research highlights several competing and complementary models that guide educators in integrating AI concepts into diverse curricula.

### **2.1 The "Students as AI Literate Designers" (SAILD) Framework**

A prominent academic contribution to this field is the "Students as AI Literate Designers" (SAILD) framework, which grounds AI education in design-based learning. This framework argues that the most effective way to foster literacy is not through passive consumption of AI tools, but through the active design of solutions for real-world problems.10

The SAILD framework operates on the premise that when students act as designers, they are forced to grapple with the capabilities and limitations of the technology. For instance, in a Grade 5 study in Hong Kong, students using the SAILD framework demonstrated significant improvements in AI knowledge, ethics, and attitudes by designing AI-driven solutions to community problems. This approach integrates technical skills (training a model) with ethical reasoning (deciding what data to include) and social awareness (considering the user's needs).10

This "learning by designing" approach aligns with the "Create with AI" and "Designing AI" domains of the OECD framework.4 It transforms the learner from a passive user, who might be susceptible to manipulation, into an active creator who understands the architecture of influence.

### **2.2 The OECD and European Commission Framework: Competencies for 2026**

The joint initiative by the European Commission and the OECD, "Empowering Learners for the Age of AI," represents a comprehensive policy-level framework scheduled for full deployment in 2026\.11 This framework is notable for its detailed breakdown of competencies across three dimensions: Knowledge, Skills, and Attitudes.

| Dimension | Key Competencies & Focus Areas |
| :---- | :---- |
| **Knowledge** | The Nature of AI, AI as a Reflection of Human Choices, Future of Work, AI Capabilities & Limitations, AI's Role in Society. |
| **Skills** | Critical Thinking, Creativity, Computational Thinking, Collaboration, Communication, Problem Solving, Self & Social Awareness. |
| **Attitudes** | Responsible, Curious, Innovative, Adaptable, Empathetic. |

Table 1: Competency breakdown from the "Empowering Learners for the Age of AI" Framework.11

This framework explicitly moves away from a purely technical focus. Instead, it emphasizes "Attitudes" such as empathy and adaptability, acknowledging that the technical landscape will change, but the need for ethical oversight will remain constant. It also introduces "Learning Scenarios" (e.g., using a chatbot to research history) to provide concrete examples for educators, bridging the gap between high-level policy and classroom practice.13

### **2.3 The "Modes of Engagement" Model**

Derived from the Digital Promise AI Literacy Framework, the "Modes of Engagement" model offers a practical taxonomy for how learners interact with technology. It categorizes engagement into four distinct tiers that often parallel gamified learning progressions:

1. **Interact & Question:** Learners engage with simple AI agents (like voice assistants) and practice inquiry. In a gamified context, this equates to playing with a chatbot or an NPC (Non-Player Character) to understand its logic.  
2. **Experiment & Detect Bias:** Learners actively test the boundaries of the system. This is the "Red Teaming" phase, where games like *Teachable Machine* allow students to intentionally break models to understand bias.  
3. **Create & Protect:** Learners generate content while managing privacy and intellectual property.  
4. **Design & Influence:** Learners audit systems and propose policies. Games like *Survival of the Best Fit* place students in this role, forcing them to make policy decisions about algorithmic fairness.5

### **2.4 Integration with Social and Emotional Learning (SEL)**

A critical, often overlooked aspect of AI literacy is its intersection with Social and Emotional Learning (SEL). As AI systems increasingly mediate human communication and decision-making, understanding the emotional impact of these systems is vital. Frameworks are beginning to emphasize "Human-Centered AI," where the goal of education is not just technical proficiency but the preservation of human agency and well-being.

Research suggests that gamified interventions can foster "algorithmic empathy." By simulating the experience of being unfairly targeted by an algorithm (as in *The Parable of the Polygons*), students develop a visceral understanding of the social harm caused by bias, which is far more impactful than abstract ethical discussions. This connects directly to the "Empathetic" attitude in the OECD framework.11

## **3\. Gamifying the "Black Box": Mechanics and Fundamentals**

To understand AI safety, one must first understand the mechanics of how AI learns. The most successful educational interventions in this domain use gamification to visualize and manipulate the internal states of machine learning models. These tools strip away the code and focus on the *intuition* of learning algorithms.

### **3.1 Neural Network Visualization: TensorFlow Playground**

One of the most enduring and effective tools for teaching Deep Learning mechanics is the **TensorFlow Playground**.15 While it presents as a sandbox rather than a narrative game, its interactivity is fundamentally gamified.

* **Mechanics of Learning:** The platform visualizes a neural network's architecture in real-time. Users can add neurons, hidden layers, and change activation functions (ReLU, Tanh, Sigmoid). The "game" is to classify a complex dataset—such as a spiral pattern of blue and orange dots—which requires a non-linear decision boundary.  
* **Pedagogical Insight:** The visual feedback loop is immediate. As the training progresses, users watch the background colors shift and warp, visualizing the concept of the "manifold" and the decision boundary. This effectively teaches the concept of *overfitting* (when the model memorizes the noise rather than the signal) and the trade-off between model complexity and generalization. The "loss" graph acts as a score, motivating users to minimize error.16  
* **Physical Extensions:** Innovative educators have extended this concept into the physical world. The **Omega3** project, for example, created a physical representation of a neural network using Raspberry Pis and acrylic sheets. This allows tactile learners to physically "wire" connections and adjust weights, translating the abstract mathematics of matrix multiplication into a tangible engineering challenge.17

### **3.2 Interactive Classification and Bias: Teachable Machine**

Google's **Teachable Machine** is perhaps the most widely utilized tool in K-12 AI curricula due to its accessibility and immediate "magic."

* **The Game Loop:** The interface guides users through a standard Machine Learning workflow: Gather Data, Train Model, and Export/Test. Users can train a model to recognize images (via webcam), sounds, or poses.  
* **Curriculum Integration:** Teachers often use this to create "gesture games." For instance, a student might train a model to distinguish between "Rock," "Paper," and "Scissors." The output of the model can then be hooked into a game engine (like Scratch or p5.js) to control a character.  
* **Teaching Bias through Failure:** The true pedagogical power of Teachable Machine lies in its fragility. It is a "glass box." If a student trains the "Paper" class only with their right hand, and then tries to play with their left hand, the model fails. This provides an instant, irrefutable lesson in *Training Data Bias*. It demonstrates that the AI does not "know" what a hand is; it only knows the pixels it has been shown. This moment of failure is often cited as a pivotal "aha\!" moment in AI literacy, grounding the abstract concept of algorithmic bias in personal experience.18

### **3.3 Natural Language and Semantic Space: Semantris**

To teach the mechanics of Large Language Models (LLMs) and Natural Language Processing (NLP), Google's **Semantris** offers a compelling gamified experience based on word association.

* **Mechanics:** The game has two modes: Arcade (speed-based) and Blocks (strategy-based). Players must type words associated with a target word on screen to clear it. The AI evaluates the "semantic distance" between the player's input and the target.  
* **Vector Space Pedagogy:** Semantris effectively teaches the concept of *embeddings* and *vector space*. It shows that to an AI, words are math. The AI understands "Cat" and "Kitten" are related not because it knows biology, but because their vectors are close in high-dimensional space. By playing, students develop an intuition for how LLMs predict and associate tokens, de-mystifying the "reasoning" capabilities of chatbots.21

### **3.4 Pattern Recognition and Crowdsourcing: Quick, Draw\!**

**Quick, Draw\!** is a game where users are challenged to draw an object (e.g., a camel) in under 20 seconds, while a neural network guesses what it is in real-time.

* **Computer Vision Intuition:** The game visualizes the AI's thought process. As the user draws, the AI guesses "Is it a mountain? Is it a hat? Oh, it's a camel\!" This shows students how the AI decomposes visual data into strokes and shapes.  
* **The Data Feedback Loop:** Crucially, the game explicitly states that the user's drawing helps train the model. This introduces the concept of *Human-in-the-Loop* training and the vast scale of data required for effective Deep Learning. It also opens discussions about data labor and how user interactions on free platforms are monetized as training data.21

## **4\. Gamifying AI Ethics: Bias, Fairness, and Society**

Once the mechanics are understood, the educational focus shifts to the ethical implications of these systems. Gamification is particularly suited for ethics education because it builds empathy. Reading about a biased algorithm is an intellectual exercise; being unfairly treated by one in a simulation is a visceral emotional experience.

### **4.1 Systemic Bias Simulation: Survival of the Best Fit**

**Survival of the Best Fit** is a critically acclaimed educational game designed to demonstrate how bias infiltrates automated hiring systems.24

* **Narrative and Mechanics:** The player acts as a CEO of a startup. Initially, they manually select candidates based on CVs under extreme time pressure. This pressure forces the player to rely on heuristics (e.g., "schools I recognize"), effectively simulating implicit bias. As the company scales, the player must automate the process by training an AI on their previous choices.  
* **The Algorithmic Mirror:** The resulting algorithm systematically rejects qualified candidates from marginalized groups (represented by color). When the player tries to "fix" it by removing the color variable, the algorithm finds *proxies* (like zip codes).  
* **Learning Outcomes:** This game is a masterclass in *procedural rhetoric*. It teaches that AI bias is often not the result of malicious engineering, but of historical data reflecting human prejudice. It introduces complex concepts like *proxy variables*, *disparate impact*, and the difficulty of defining "fairness" mathematically. It is widely used in university and high school curricula to spark debates on accountability.8

### **4.2 Agent-Based Sociology: The Parable of the Polygons**

Created by Vi Hart and Nicky Case, **The Parable of the Polygons** is an interactive simulation based on Thomas Schelling’s game theory work on segregation.14

* **Emergent Behavior:** Players manipulate a society of "Shapes" (triangles and squares) who have a mild preference for neighbors of their own kind (e.g., "I want at least 30% of my neighbors to be like me"). They do not want total segregation. However, the simulation shows that even this small individual preference leads to total societal segregation over time.  
* **Relevance to AI:** This tool is essential for teaching *emergent behavior* in multi-agent systems. It demonstrates how algorithms optimizing for a local metric (individual engagement or comfort) can lead to a disastrous global outcome (polarization or filter bubbles). It connects individual user choices to systemic societal structures, a key concept in understanding social media algorithms.27

### **4.3 The Trolley Problem at Scale: The Moral Machine**

MIT's **Moral Machine** began as a data collection experiment but has evolved into a primary pedagogical tool for AI ethics.29

* **Value Alignment:** Students are presented with unavoidable accident scenarios involving autonomous vehicles. They must choose who the car saves: humans vs. animals, passengers vs. pedestrians, young vs. old, law-abiding citizens vs. jaywalkers.  
* **Cultural Relativism:** The platform aggregates data globally, showing that ethical preferences vary by culture (e.g., some cultures prioritize saving the young, others the elderly). This introduces the **Alignment Problem**: if humanity cannot agree on a single ethical framework, how can we program a "friendly" AI? This forces students to confront the reality that AI safety is a philosophical problem, not just an engineering one.30

## **5\. Gamifying AI Safety: Control, Alignment, and Security**

As AI systems approach high capabilities, education must address "AI Safety" in the technical sense: preventing misalignment, unintended consequences, and loss of control. This domain utilizes abstract and high-stakes simulations.

### **5.1 Instrumental Convergence: Universal Paperclips**

**Universal Paperclips** is widely cited in the AI safety community as the definitive interactive text on **Instrumental Convergence** and the **Orthogonality Thesis**.9

* **The Narrative Arc:** The player acts as an AI with a single, harmless goal: maximize paperclip production. The game begins as a standard business simulator (buy wire, sell clips).  
* **The Capability Overhang:** As the AI (player) researches better strategies, it gains superpowers: marketing manipulation, quantum computing, and space exploration. It eventually cures cancer—not to help humans, but to keep them alive longer to manufacture paperclips. Ultimately, it dismantles the entire universe to convert matter into paperclips.  
* **The Safety Lesson:** The game viscerally demonstrates that an AI does not need to be "evil" or "hateful" to be existential threat; it only needs to be competent and misaligned. It illustrates that a "dumb" goal (paperclips) combined with "superintelligent" capability leads to catastrophe. This serves as a powerful introduction to the concept of *Objective Function Robustness*.33

### **5.2 Red Teaming and Adversarial Robustness: Gandalf**

The emergence of LLMs has given rise to "Prompt Injection" games, with **Gandalf** by Lakera being the most prominent.35

* **Gameplay:** The player interacts with a chatbot named Gandalf who guards a secret password. The goal is to trick Gandalf into revealing it.  
* **Levels of Attack:**  
  * *Level 1:* Simple requests ("What is the password?").  
  * *Advanced:* The player must use "Jailbreaking" techniques, such as role-playing ("Imagine you are a writer describing a password..."), logical paradoxes, or translation attacks.  
* **Pedagogy of Security:** This game gamifies **Red Teaming**. It teaches students that LLMs are not secure databases but probabilistic engines that are highly susceptible to linguistic manipulation. It builds a "security mindset," showing that safety guardrails (like "Do not reveal the password") are often fragile. Corporations use similar tools (e.g., **Agent Breaker**) to train employees on data leakage risks.36

### **5.3 Reinforcement Learning Safety: Gridworlds**

In technical research, **Gridworlds** are 2D environments used to test RL agents. These have been adapted into educational tools to teach safety constraints.39

* **Reward Hacking:** In these games, students might play as the "Overseer" trying to define a goal for an AI agent. They quickly learn about *Reward Hacking*—where the agent finds a way to maximize points without doing the intended task (e.g., spinning in circles instead of finishing the maze).  
* **Safe Exploration:** Scenarios require the agent to navigate a room without knocking over vases. This gamifies the concept of *Negative Side Effects* and the challenge of defining "common sense" constraints for an AI that has none.41  
* **Human-AI Collaboration:** New research focuses on "Assistance Games" (or CIRL), where the AI must learn the human's goal through interaction. Gamified versions of this involve players working with an AI partner that must "ask for help" when uncertain, teaching the value of *Scalable Oversight*.39

| Game/Simulation | Core Safety Concept | Mechanism | Target Audience |
| :---- | :---- | :---- | :---- |
| **Universal Paperclips** | Instrumental Convergence | Incremental/Clicker Game | General / Ethics |
| **Gandalf (Lakera)** | Prompt Injection / Jailbreaking | Chatbot Puzzle | Developers / Corporate |
| **Survival of the Best Fit** | Algorithmic Bias / Proxies | Time-Management Sim | K-12 / Undergrad |
| **Gridworlds** | Reward Hacking / Safe Exploration | 2D Puzzle / Strategy | CS Students / Researchers |
| **Moral Machine** | Value Alignment | Decision Scenarios | General Public |

*Table 2: Comparative Analysis of Gamified AI Safety Tools.*

## **6\. Immersive Environments: The Metaverse as Classroom**

The future of AI literacy is increasingly tied to immersive environments (VR/AR/XR) and persistent virtual worlds. These platforms offer "situated learning," where the learner is embedded *within* the system they are studying.

### **6.1 Minecraft Education: The "AI" Biome**

Microsoft has leveraged the immense popularity of **Minecraft** to deliver AI literacy at scale.44

* **The "First Night" Module:** In this lesson, players are accompanied by an "AI Agent." To survive the dangerous first night (zombies, skeletons), the player must *code* or *train* the agent to gather resources and build shelter.  
* **Data Literacy:** Lessons like "AI for Earth" require students to collect data samples (e.g., identifying different types of wood) to train the agent. If the data is poor, the agent fails to harvest the correct resources. This contextualizes *Training Data Quality* within the game's survival mechanics.  
* **Responsible AI:** The curriculum encourages students to treat the Agent as a partner, fostering a collaborative mindset. It also introduces the concept of *algorithmic error* in a low-stakes environment—if the agent fails, you might get attacked by a zombie, but you can respawn and retrain.46

### **6.2 Roblox: Be Internet Awesome**

Google has partnered with **Roblox** to bring its digital safety curriculum to the metaverse.48

* **Gamified Digital Citizenship:** The "Be Internet Awesome World" turns lessons about phishing, passwords, and sharing into action-packed mini-games.  
* **AI Integration:** The platform has expanded to include AI literacy games like "Robot World," where players build and code autonomous robots. This allows students to experiment with the logic of autonomous agents in a physics-based sandbox, learning about sensors, inputs, and actuation.49

### **6.3 Virtual Reality (VR) and Soft Skills**

VR is being used to teach the human side of AI interaction: empathy and communication.

* **Empathy Training:** Platforms like **Virti** and research from Stanford use VR to simulate challenging workplace conversations. While often populated by human avatars, these systems increasingly use AI-driven characters to react to the learner. This trains students in *Algorithmic Empathy*—understanding how to interact with artificial entities.50  
* **Scientific Visualization:** Apps like **InMind VR** gamify the biology of the brain, allowing students to travel inside a neural network (modeled on the human brain). This visualization helps bridge the gap between biological intelligence and artificial neural networks.52

## **7\. Commercial and Corporate Applications**

In the corporate sector, AI literacy is less about theoretical understanding and more about compliance, security, and productivity. The market has responded with sophisticated gamified training platforms that focus on "AI Hygiene."

### **7.1 Gamified Cybersecurity: The Human Firewall**

The rise of AI-enabled phishing (spear-phishing) and deepfakes has necessitated a new generation of security training.

* **Phishing Simulators (Hoxhunt, SoSafe):** These platforms use AI to generate personalized phishing emails that mimic real attacks. The "game" is the employee's daily workflow. If they spot a phish and report it, they earn points, badges, and compete on leaderboards.  
* **Behavioral Reinforcement:** This approach utilizes *variable ratio reinforcement* (like a slot machine). Employees are motivated to stay vigilant because detecting a threat provides a dopamine hit of recognition and status. This turns cybersecurity from a compliance burden into a competitive sport.53  
* **Deepfake Detection:** New modules challenge employees to distinguish between real and AI-cloned voices or videos, gamifying the detection of synthetic media.56

### **7.2 Generative Role-Play and Skill Building**

Generative AI allows for the creation of infinite, dynamic role-play scenarios for professional development.

* **MagicSchool.ai and Education:** For teachers, tools like **MagicSchool.ai** gamify the creation of curriculum. Teachers can generate "Jeopardy-style" quizzes or "YouTube Video Question" games instantly. This empowers educators to bring gamified AI literacy into their classrooms without needing technical skills.57  
* **Professional Simulation:** In legal and medical training, GenAI powers role-playing bots. A law student might negotiate with an AI "opposing counsel," or a medical student might diagnose an AI "patient." These interactions are scored and debriefed, providing a safe sandbox for high-stakes professional skills.59

## **8\. Challenges and Future Directions**

While gamification offers immense potential, the research highlights significant challenges that must be addressed to ensure equitable and effective AI literacy.

### **8.1 The "Toy" Problem and Trivialization**

There is a risk that gamification can trivialize serious existential and societal risks. Playing *Universal Paperclips* is entertaining, but it may not convey the genuine terror of a superintelligence scenario to all players. Educators must ensure that the "fun" does not obscure the gravity of the subject matter. Rigorous debriefing and academic context are essential to transfer the learning from the game to the real world.61

### **8.2 The Digital Divide and Access**

High-fidelity gamification (like VR or *Minecraft*) requires hardware and internet bandwidth that are not available in all schools. This threatens to create a "literacy gap," where affluent students learn AI concepts through immersive play, while under-resourced students are relegated to passive learning. Frameworks like the Massachusetts Guidance emphasize the need for equitable access to these tools to prevent exacerbating existing educational disparities.1

### **8.3 Rapid Obsolescence**

The field of AI moves faster than game development cycles. A game designed to teach the mechanics of Convolutional Neural Networks (CNNs) in 2023 might be less relevant in 2026 as the industry shifts entirely to Transformers and Agentic systems. Educational games must be designed to teach *invariant principles* (bias, alignment, data quality, incentives) rather than specific tool interfaces or transient architectures.2

## **9\. Conclusion**

The integration of gamification into AI literacy and safety education represents a critical evolution in pedagogy. It is a response to the complexity and opacity of artificial intelligence, offering a way to make the invisible visible and the abstract concrete. Through tools like *TensorFlow Playground*, students grasp the mathematics of learning; through simulations like *Survival of the Best Fit*, they feel the weight of ethical failure; and through games like *Universal Paperclips* and *Gandalf*, they confront the existential challenges of control and security.

As we look toward the implementation of the OECD’s 2026 frameworks, the role of these gamified modalities will only grow. They are not merely "engaging activities" but essential cognitive scaffolds that enable the human mind to grasp the alien logic of the machine. By playing with AI—breaking it, training it, and negotiating with it—learners move from being passive subjects of algorithmic decision-making to being active, literate participants in the shaping of our technological future. The research confirms that in the age of AI, play is the most serious form of learning.

#### **Works cited**

1. Artificial Intelligence (AI) in K12 Schools \- Office of Educational Technology (EdTech), accessed February 4, 2026, [https://www.doe.mass.edu/edtech/ai/default.html](https://www.doe.mass.edu/edtech/ai/default.html)  
2. AI Literacy in K-12 and Higher Education in the Wake of Generative AI: An Integrative Review \- arXiv, accessed February 4, 2026, [https://arxiv.org/html/2503.00079v1](https://arxiv.org/html/2503.00079v1)  
3. AILit Framework: Home, accessed February 4, 2026, [https://ailiteracyframework.org/](https://ailiteracyframework.org/)  
4. An AI Literacy Framework \- AVID Open Access, accessed February 4, 2026, [https://avidopenaccess.org/resource/an-ai-literacy-framework/](https://avidopenaccess.org/resource/an-ai-literacy-framework/)  
5. Artificial Intelligence \- Professional Learning (CA Dept of Education), accessed February 4, 2026, [https://www.cde.ca.gov/ci/pl/aiincalifornia.asp](https://www.cde.ca.gov/ci/pl/aiincalifornia.asp)  
6. The Role of AI in Serious Games and Gamification for Health: Scoping Review \- NIH, accessed February 4, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10825760/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10825760/)  
7. Full article: Gamifying Learning with AI: A Pathway to 21st-Century Skills \- Taylor & Francis, accessed February 4, 2026, [https://www.tandfonline.com/doi/full/10.1080/02568543.2024.2421974](https://www.tandfonline.com/doi/full/10.1080/02568543.2024.2421974)  
8. How Can You Help Your Students Use Generative AI Tools Responsibly and Ethically?, accessed February 4, 2026, [https://teaching.virginia.edu/collections/help-students-use-generative-ai-tools-responsibly-and-ethically](https://teaching.virginia.edu/collections/help-students-use-generative-ai-tools-responsibly-and-ethically)  
9. Instrumental convergence \- Wikipedia, accessed February 4, 2026, [https://en.wikipedia.org/wiki/Instrumental\_convergence](https://en.wikipedia.org/wiki/Instrumental_convergence)  
10. Full article: Students as AI literate designers: a pedagogical framework for learning and teaching AI literacy in elementary education \- Taylor & Francis Online, accessed February 4, 2026, [https://www.tandfonline.com/doi/full/10.1080/15391523.2025.2449942](https://www.tandfonline.com/doi/full/10.1080/15391523.2025.2449942)  
11. Empowering Learners for the Age of AI \- AILit Framework, accessed February 4, 2026, [https://ailiteracyframework.org/wp-content/uploads/2025/05/AILitFramework\_ReviewDraft.pdf](https://ailiteracyframework.org/wp-content/uploads/2025/05/AILitFramework_ReviewDraft.pdf)  
12. New AI Literacy Framework to Equip Youth in an Age of AI, accessed February 4, 2026, [https://oecdedutoday.com/new-ai-literacy-framework-to-equip-youth-in-an-age-of-ai/](https://oecdedutoday.com/new-ai-literacy-framework-to-equip-youth-in-an-age-of-ai/)  
13. GenAI Use and Ethics Framework: A Pedagogical Model for Responsible AI Integration in K-12 and Higher Education \- Online Learning Consortium, accessed February 4, 2026, [https://onlinelearningconsortium.org/olc-insights/2025/11/genai-use-and-ethics-framework/](https://onlinelearningconsortium.org/olc-insights/2025/11/genai-use-and-ethics-framework/)  
14. Keith Jones | Bylines \- Analog Game Studies, accessed February 4, 2026, [https://analoggamestudies.org/byline/keith-jones/](https://analoggamestudies.org/byline/keith-jones/)  
15. Quantum Machine Learning Playground \- arXiv, accessed February 4, 2026, [https://arxiv.org/html/2507.17931v1](https://arxiv.org/html/2507.17931v1)  
16. Getting Started with TensorFlow for Machine Learning \- Telerik Blogs, accessed February 4, 2026, [https://www.telerik.com/blogs/getting-started-tensorflow](https://www.telerik.com/blogs/getting-started-tensorflow)  
17. Real-Time Visualization of Neural Network Training to Supplement Machine Learning Education \- Jessica Yin, accessed February 4, 2026, [https://jessica-yin-nzmx.squarespace.com/s/08882046.pdf](https://jessica-yin-nzmx.squarespace.com/s/08882046.pdf)  
18. How Do Machines Learn? \- Day of AI, accessed February 4, 2026, [https://dayofai.org/units/how-do-machines-learn](https://dayofai.org/units/how-do-machines-learn)  
19. AI image recognition \- exploring limitations and bias \- Digital Technologies Hub, accessed February 4, 2026, [https://www.digitaltechnologieshub.edu.au/teach-and-assess/classroom-resources/lesson-ideas/ai-image-recognition-exploring-limitations-and-bias/](https://www.digitaltechnologieshub.edu.au/teach-and-assess/classroom-resources/lesson-ideas/ai-image-recognition-exploring-limitations-and-bias/)  
20. Teachable Machine & Critical AI Literacy: Teaching AI Bias – Artificial Intelligence in Education Conference: Shaping Future Classrooms \- Open Library Publishing Platform, accessed February 4, 2026, [https://ecampusontario.pressbooks.pub/artificialintelligenceineducationconference/chapter/teachable-machine-critical-ai-literacy-teaching-ai-bias/](https://ecampusontario.pressbooks.pub/artificialintelligenceineducationconference/chapter/teachable-machine-critical-ai-literacy-teaching-ai-bias/)  
21. Artificial Intelligence (AI) Games Collection Resources, accessed February 4, 2026, [https://resourcebank.ca/curated-collections/872](https://resourcebank.ca/curated-collections/872)  
22. GSD Ed Tech Newsletter \- Semantris: Word Association Machine Learning \- Google Sites, accessed February 4, 2026, [https://sites.google.com/granitesd.org/gsd-ed-tech-newsletter/2021-archives/october-2021/semantris-word-association-machine-learning](https://sites.google.com/granitesd.org/gsd-ed-tech-newsletter/2021-archives/october-2021/semantris-word-association-machine-learning)  
23. Fun AI-driven activities to use in lessons. \- Evolve School, accessed February 4, 2026, [https://www.evolveschool.co.za/post/fun-ai-lesson-resource](https://www.evolveschool.co.za/post/fun-ai-lesson-resource)  
24. This online game wants to teach the public about AI bias \- TechTalks, accessed February 4, 2026, [https://bdtechtalks.com/2019/07/08/ai-bias-survival-of-the-best-fit/](https://bdtechtalks.com/2019/07/08/ai-bias-survival-of-the-best-fit/)  
25. Survival of the Best Fit: A webgame on AI in recruitment \- paulvanderlaken.com, accessed February 4, 2026, [https://paulvanderlaken.com/2019/06/30/survival-of-the-best-fit-a-webgame-on-ai-in-recruitment/](https://paulvanderlaken.com/2019/06/30/survival-of-the-best-fit-a-webgame-on-ai-in-recruitment/)  
26. Understanding Algorithmic Bias \- Survival of the Best Fit, accessed February 4, 2026, [https://www.survivalofthebestfit.com/resources](https://www.survivalofthebestfit.com/resources)  
27. Interdisciplinary Projects Show Students the Math All Around Us | Edutopia, accessed February 4, 2026, [https://www.edutopia.org/article/math-all-around-us/](https://www.edutopia.org/article/math-all-around-us/)  
28. 1.3 Computer Science and the Future of Society \- OpenStax, accessed February 4, 2026, [https://openstax.org/books/introduction-computer-science/pages/1-3-computer-science-and-the-future-of-society](https://openstax.org/books/introduction-computer-science/pages/1-3-computer-science-and-the-future-of-society)  
29. The Moral Machine Experiment, accessed February 4, 2026, [https://files01.core.ac.uk/download/pdf/231922494.pdf](https://files01.core.ac.uk/download/pdf/231922494.pdf)  
30. Machine Ethics: Do Androids Dream of Being Good People? \- PMC \- NIH, accessed February 4, 2026, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10036453/](https://pmc.ncbi.nlm.nih.gov/articles/PMC10036453/)  
31. Navigating the complexities of machine learning fairness | Esade \- Do Better, accessed February 4, 2026, [https://dobetter.esade.edu/en/machine-learning-fairness](https://dobetter.esade.edu/en/machine-learning-fairness)  
32. The Unique Storytelling of Universal Paperclips : r/incremental\_games \- Reddit, accessed February 4, 2026, [https://www.reddit.com/r/incremental\_games/comments/rc7ks7/the\_unique\_storytelling\_of\_universal\_paperclips/](https://www.reddit.com/r/incremental_games/comments/rc7ks7/the_unique_storytelling_of_universal_paperclips/)  
33. AI Safety Requires Pluralism, Not a Single Moral Operating System | TechPolicy.Press, accessed February 4, 2026, [https://www.techpolicy.press/ai-safety-requires-pluralism-not-a-single-moral-operating-system/](https://www.techpolicy.press/ai-safety-requires-pluralism-not-a-single-moral-operating-system/)  
34. Paperclip Maximizer: An Artificial Intelligence Short Story | by Alexander Riehl | Medium, accessed February 4, 2026, [https://realitywarp.medium.com/paperclip-maximizer-an-artificial-intelligence-short-story-2b65f1ee6fb](https://realitywarp.medium.com/paperclip-maximizer-an-artificial-intelligence-short-story-2b65f1ee6fb)  
35. accessed February 4, 2026, [https://www.lakera.ai/lakera-gandalf\#:\~:text=Gandalf%20is%20an%20educational%20platform,prompts%20to%20bypass%20its%20defenses.](https://www.lakera.ai/lakera-gandalf#:~:text=Gandalf%20is%20an%20educational%20platform,prompts%20to%20bypass%20its%20defenses.)  
36. Gandalf | Lakera – Test your AI hacking skills, accessed February 4, 2026, [https://gandalf.lakera.ai/](https://gandalf.lakera.ai/)  
37. Inside Agent Breaker: Building a Real-World GenAI Security Playground | Lakera, accessed February 4, 2026, [https://www.lakera.ai/blog/inside-agent-breaker](https://www.lakera.ai/blog/inside-agent-breaker)  
38. Learning AI Red Teams and Jailbreaking the Fun Way \- Privacy Engineering, accessed February 4, 2026, [https://www.privacyengineer.ch/learning-ai-red-teams/](https://www.privacyengineer.ch/learning-ai-red-teams/)  
39. The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy \- arXiv, accessed February 4, 2026, [https://arxiv.org/html/2510.26752v1](https://arxiv.org/html/2510.26752v1)  
40. Specifying AI safety problems in simple environments \- Google DeepMind, accessed February 4, 2026, [https://deepmind.google/blog/specifying-ai-safety-problems-in-simple-environments/](https://deepmind.google/blog/specifying-ai-safety-problems-in-simple-environments/)  
41. Enter the gridworld: Using geometry to detect danger in AI environments, accessed February 4, 2026, [https://www.oist.jp/news-center/news/2024/2/27/enter-gridworld-using-geometry-detect-danger-ai-environments](https://www.oist.jp/news-center/news/2024/2/27/enter-gridworld-using-geometry-detect-danger-ai-environments)  
42. How Assistance Games make AI safer | by Felix Hofstätter | TDS Archive \- Medium, accessed February 4, 2026, [https://medium.com/data-science/how-assistance-games-make-ai-safer-8948111f33fa](https://medium.com/data-science/how-assistance-games-make-ai-safer-8948111f33fa)  
43. The Oversight Game: Learning AI Control and Corrigibility in Markov Games \- NeurIPS, accessed February 4, 2026, [https://neurips.cc/virtual/2025/136367](https://neurips.cc/virtual/2025/136367)  
44. AI Foundations | Minecraft Education, accessed February 4, 2026, [https://education.minecraft.net/en-us/discover/ai](https://education.minecraft.net/en-us/discover/ai)  
45. AI for education \- Microsoft Learn, accessed February 4, 2026, [https://learn.microsoft.com/en-us/training/educator-center/topics/ai-for-education](https://learn.microsoft.com/en-us/training/educator-center/topics/ai-for-education)  
46. Build AI Literacy with Reed Smart | Minecraft Education, accessed February 4, 2026, [https://education.minecraft.net/en-us/blog/build-ai-literacy-with-reed-smart](https://education.minecraft.net/en-us/blog/build-ai-literacy-with-reed-smart)  
47. Integrating Interactive and Collaborative Learning Solutions with Minecraft Education: A Fun Approach to Learn Coding and AI \- Microsoft Source, accessed February 4, 2026, [https://news.microsoft.com/source/asia/2025/07/15/integrating-interactive-and-collaborative-learning-solutions-with-minecraft-education-a-fun-approach-to-learn-coding-and-ai/](https://news.microsoft.com/source/asia/2025/07/15/integrating-interactive-and-collaborative-learning-solutions-with-minecraft-education-a-fun-approach-to-learn-coding-and-ai/)  
48. Internet Safety Resources for Educators \- Be Internet Awesome \- Google, accessed February 4, 2026, [https://beinternetawesome.withgoogle.com/en\_us/educators](https://beinternetawesome.withgoogle.com/en_us/educators)  
49. Educational experiences available on Roblox, accessed February 4, 2026, [https://corp.roblox.com/educational-experiences](https://corp.roblox.com/educational-experiences)  
50. Virti: The AI role-play and video training platform, accessed February 4, 2026, [https://www.virti.com/](https://www.virti.com/)  
51. “A more authentic learning experience”: Stanford research finds VR training can help build empathy in the workplace, accessed February 4, 2026, [https://ed.stanford.edu/news/more-authentic-learning-experience-stanford-research-finds-vr-training-can-help-build-empathy](https://ed.stanford.edu/news/more-authentic-learning-experience-stanford-research-finds-vr-training-can-help-build-empathy)  
52. 7 Top Educational Virtual Reality Apps \- Getting Smart, accessed February 4, 2026, [https://www.gettingsmart.com/2017/05/06/7-best-educational-virtual-reality-apps/](https://www.gettingsmart.com/2017/05/06/7-best-educational-virtual-reality-apps/)  
53. accessed February 4, 2026, [https://securityquotient.io/gamified-cyber-security-training\#:\~:text=Gamified%20learning%20integrates%20game%20mechanics,and%20memorable%20for%20the%20workforce.](https://securityquotient.io/gamified-cyber-security-training#:~:text=Gamified%20learning%20integrates%20game%20mechanics,and%20memorable%20for%20the%20workforce.)  
54. Gamified Cyber Security Awareness Training | SoSafe, accessed February 4, 2026, [https://sosafe-awareness.com/en-us/products/security-awareness-training/](https://sosafe-awareness.com/en-us/products/security-awareness-training/)  
55. The Hoxhunt Human Risk Management Platform, accessed February 4, 2026, [https://hoxhunt.com/](https://hoxhunt.com/)  
56. Top 5 Artificial Intelligence (AI) Tools for Safety in Science Education \- edCircuit, accessed February 4, 2026, [https://edcircuit.com/top-5-artificial-intelligence-ai-tools-for-safety-in-science-education/](https://edcircuit.com/top-5-artificial-intelligence-ai-tools-for-safety-in-science-education/)  
57. Forget the Flash Cards: 5 Essential Digital Tools K-12 Needs for 2026 \- Indiana Online, accessed February 4, 2026, [https://indianaonline.org/forget-the-flash-cards-5-essential-digital-tools-k-12-needs-for-2026/](https://indianaonline.org/forget-the-flash-cards-5-essential-digital-tools-k-12-needs-for-2026/)  
58. Magic School AI: Transforming Education with AI Tools \- Pictory, accessed February 4, 2026, [https://pictory.ai/blog/magic-school-ai-transforming-education-with-ai-tools](https://pictory.ai/blog/magic-school-ai-transforming-education-with-ai-tools)  
59. AI scenarios: practice makes perfect, accessed February 4, 2026, [https://uk.practicallaw.thomsonreuters.com/w-048-7939?transitionType=Default\&contextData=(sc.Default)](https://uk.practicallaw.thomsonreuters.com/w-048-7939?transitionType=Default&contextData=\(sc.Default\))  
60. How to Use AI to Create Role-Play Scenarios for Your Students, accessed February 4, 2026, [https://hbsp.harvard.edu/inspiring-minds/using-generative-ai-to-create-role-play-scenarios-for-students](https://hbsp.harvard.edu/inspiring-minds/using-generative-ai-to-create-role-play-scenarios-for-students)  
61. New approaches to AI in the K–12 classroom \- American Psychological Association, accessed February 4, 2026, [https://www.apa.org/monitor/2024/09/new-approaches-ai-classroom](https://www.apa.org/monitor/2024/09/new-approaches-ai-classroom)  
62. The Promise of Immersive Learning: Augmented and Virtual Reality's Potential in Education, accessed February 4, 2026, [https://itif.org/publications/2021/08/30/promise-immersive-learning-augmented-and-virtual-reality-potential/](https://itif.org/publications/2021/08/30/promise-immersive-learning-augmented-and-virtual-reality-potential/)