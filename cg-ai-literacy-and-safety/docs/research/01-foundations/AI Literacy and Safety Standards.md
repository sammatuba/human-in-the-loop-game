# **The Architecture of Algorithmic Citizenship: A Comprehensive Global Standard for AI Literacy and Safety**

## **1\. Executive Synthesis and Strategic Imperative**

The pervasive integration of Artificial Intelligence (AI) into the foundational strata of modern society—ranging from healthcare diagnostics and judicial sentencing to financial modeling and creative expression—has precipitated a critical juncture in human development. We are witnessing the transition from the "Information Age," defined by the access to data, to the "Algorithmic Age," defined by the automated processing and generative interpretation of that data. In this new epoch, the definition of "literacy" must expand beyond the traditional competencies of reading, writing, and numeracy to encompass **AI Literacy**: the critical, technical, and ethical competencies required to exercise agency in a world increasingly mediated by autonomous systems.

This report establishes a rigorous, exhaustive evidence base for the development of interactive coursework designed for the general population. It synthesizes the normative frameworks of the world’s most credible institutions—including the **Organisation for Economic Co-operation and Development (OECD)**, the **United Nations Educational, Scientific and Cultural Organization (UNESCO)**, the **Council of Europe (CoE)**, the **European Union (EU)**, and the **National Institute of Standards and Technology (NIST)**. These institutions have moved beyond vague aspirations to define precise standards for "Trustworthy AI," "Human-Centric AI," and "AI Safety."

### **1.1 The Shift from User to Auditor**

A central theme emerging from this analysis is the fundamental shift in the role of the human operator. Early digital literacy focused on *usage*—how to operate a computer, how to search the web. The emerging global standards for AI literacy focus on *auditability* and *agency*. It is no longer sufficient for a citizen to know how to prompt a Large Language Model (LLM); they must possess the epistemic tools to evaluate the veracity of its output, the ethical tools to assess its bias, and the civic tools to govern its deployment.1

The curriculum for the general population must therefore be structured not merely as technical training, but as a form of **civic defense**. The "Human-in-the-Loop" (HITL) is not just a technical safeguard but a civic responsibility. The standards analyzed herein collectively argue that safety is not a feature inherent to the machine, but a dynamic state achieved through the competent oversight of a literate human operator.3

### **1.2 The Three Pillars of the Global Standard**

The synthesis of international frameworks reveals three non-negotiable pillars for any credible AI literacy curriculum:

1. **Technological Demystification:** Citizens must understand that AI systems are probabilistic, data-dependent constructs, not magical or sentient entities. This "glass box" understanding is crucial for dispelling anthropomorphic fallacies.5  
2. **Risk Management as a Life Skill:** The ability to "Map, Measure, and Manage" risk—terminology borrowed from NIST—must be translated into personal habits for data privacy, skepticism, and decision-making.7  
3. **Human Agency and Rights:** The curriculum must instill the "Human-Centric Mindset" (UNESCO) and the "Human Dimension" (CoE), ensuring that learners prioritize human dignity, democracy, and rule of law over algorithmic efficiency.1

This report is structured to guide the translation of these high-level policy documents into granular, interactive learning objectives. It provides the intellectual architecture necessary to build a curriculum that is globally compliant, ethically robust, and pedagogically effective.

## ---

**2\. The Philosophical Foundations of Human-Centric AI**

To build a curriculum that endures beyond the current hype cycle, one must ground it in the philosophical principles that drive global governance. The terminology used by credible institutions—"Trustworthy," "Robust," "Inclusive"—is derived from a specific ethical stance: that technology must serve humanity, not the other way around.

### **2.1 The OECD Value-Based Principles: The Global North Star**

The **OECD AI Principles**, adopted in 2019 and updated in 2024 to address the challenges of generative AI, represent the first intergovernmental standard on AI.10 These principles have been endorsed by 47 countries, making them the most widely accepted baseline for "Responsible AI." For a public education curriculum, the OECD’s five "Values-based principles" serve as the primary learning objectives for ethical literacy.

#### **2.1.1 Inclusive Growth, Sustainable Development, and Well-being**

The first principle emphasizes that AI should drive beneficial outcomes for people and the planet.10 This challenges the narrative that AI is purely for corporate efficiency.

* **Curriculum Context:** Interactive coursework must teach learners to evaluate AI applications through a holistic lens. "Is this tool sustainable?" is a literacy question.  
* **Deep Insight:** The 2024 updates highlight the protection of natural environments. A comprehensive curriculum should include modules on the *physicality* of AI—the energy consumption of data centers and the environmental cost of training large models. This grounds the "cloud" in reality for the learner.12

#### **2.1.2 Human-Centred Values and Fairness**

This is the core of the "Human-in-Command" philosophy. AI systems must respect the rule of law, human rights, and democratic values.13

* **Specific Requirement:** The OECD explicitly mentions "fairness and privacy." In a classroom setting, this translates to understanding *bias*.  
* **Interactive Application:** Learners should be exposed to scenarios where an AI system technically "works" (i.e., maximizes an objective function) but fails ethically (e.g., discriminating against a minority group). The competency to identify and reject such outcomes is a key literacy metric.15

#### **2.1.3 Transparency and Explainability**

The "Black Box" problem is a central theme. The OECD mandates that AI actors provide meaningful information appropriate to the context.16

* **Nuance for General Public:** Transparency does not require the user to read code. It requires "meaningful information." This includes knowing *when* they are interacting with an AI (a requirement also echoed in the EU AI Act) and understanding the *factors* that influenced a decision.  
* **Curriculum Component:** "The Right to Explanation." Citizens must be taught how to ask: "What data was this based on?" and "What logic did the system use?".14

#### **2.1.4 Robustness, Security, and Safety**

AI systems must function appropriately and not pose unreasonable safety risks.10

* **Safety Definition:** The OECD definition of safety includes "traceability" and "risk management." It is not just about physical safety (robots) but informational safety (misinformation).  
* **2024 Update:** The revised principles explicitly address "misinformation and disinformation amplified by AI".15 This elevates **Media Literacy** to a component of AI Safety.

#### **2.1.5 Accountability**

There must be accountability for AI systems.11

* **Civic Lesson:** The machine is never responsible; the human/organization is. This counters the "the algorithm did it" defense. Coursework must emphasize the chain of responsibility.

### **2.2 The Council of Europe: Democracy and the Rule of Law**

While the OECD focuses on economic and social well-being, the **Council of Europe (CoE)** approaches AI from a strict human rights perspective. Their contribution to the literacy debate is the identification of the "Human Dimension" gap.9

#### **2.2.1 The Three-Dimensional Literacy Framework**

The CoE critiques current education for focusing too heavily on technical skills. They propose a tripartite definition 9:

1. **The Technological Dimension:** Understanding the underlying mechanisms (Data ![][image1] Algorithm ![][image1] Output). This includes knowledge of statistics and computing.  
2. **The Practical Dimension:** Skills to use AI tools effectively for work or life. This is the "how-to" component.  
3. **The Human Dimension:** *The critical differentiator.* This involves understanding AI's impact on human rights, human agency, democracy, and the rule of law.

**Implication for Coursework:** A curriculum that teaches someone how to prompt ChatGPT (Practical) and how LLMs work (Technological) but fails to discuss the impact of deepfakes on elections (Human) is *incomplete* and *sub-standard* according to the CoE. The Human Dimension requires teaching "Epistemic Safety"—how to protect one's perception of reality.9

### **2.3 The EU Ethics Guidelines for Trustworthy AI**

The European Union’s High-Level Expert Group (HLEG) produced the "Ethics Guidelines for Trustworthy AI," which outlines seven key requirements. These serve as excellent "evaluation rubrics" for the general public.3

| Requirement | Description for General Public | Learning Objective (Coursework) |
| :---- | :---- | :---- |
| **1\. Human Agency & Oversight** | Users should not be manipulated; humans must remain in control. | Identify "Dark Patterns" where AI nudges behavior. Understand HITL (Human-in-the-Loop) vs. HIC (Human-in-Command). |
| **2\. Technical Robustness & Safety** | The system should not fail easily or be hacked. | Understand "Adversarial Attacks" and "Data Poisoning." Realize AI is fragile. |
| **3\. Privacy & Data Governance** | You own your data; the AI shouldn't steal it. | Recognize inference risks: AI guessing private info (e.g., sexuality) from public data. |
| **4\. Transparency** | Be told when you are talking to a bot. | Identify markers of synthetic media (Deepfakes). Demand disclosure. |
| **5\. Diversity & Fairness** | The AI shouldn't be racist or sexist. | Test a model for bias (e.g., prompt for "Doctor" vs. "Nurse"). |
| **6\. Societal Well-being** | Is this good for society? | Debate the impact of AI on local employment, social bonding, and democracy. |
| **7\. Accountability** | Who is to blame when it breaks? | Distinguish responsibility between "Developer" (builder) and "Deployer" (user). |

Deep Dive on Human Oversight 3: The EU framework distinguishes three levels of oversight, which can be gamified in coursework:

* **Human-in-the-Loop (HITL):** Human intervention in every decision cycle.  
* **Human-on-the-Loop (HOTL):** Human oversight of the system design and monitoring operation.  
* **Human-in-Command (HIC):** The authority to decide *not* to use the system.  
* *Curriculum Note:* Teach scenarios where HIC is the only ethical choice (e.g., a lethal autonomous weapon scenario or a biased judicial algorithm).

## ---

**3\. Comprehensive Competency Frameworks (The "What")**

Having established the *why* (Values), we must now define the *what* (Competencies). The most granular and rigorous standard for this comes from **UNESCO**.

### **3.1 UNESCO AI Competency Frameworks (Students & Teachers)**

UNESCO has released two defining documents: the **AI Competency Framework for Students (AI CFS)** and **Teachers (AI CFT)**. These are designed to guide national curricula and are essential for any credible public education program.1

#### **3.1.1 The Four Dimensions of Competency**

UNESCO organizes literacy into four domains. These should form the modules of the interactive coursework 18:

1. **Human-Centred Mindset:**  
   * *Concept:* Agency. The belief that humans shape technology.  
   * *Key Competency:* "Understanding and asserting human agency."  
   * *Learning Objective:* Students should be able to articulate how AI impacts human rights and sustainable development.  
2. **Ethics of AI:**  
   * *Concept:* Responsible use, "Ethics-by-Design."  
   * *Key Competency:* "Safe and responsible use."  
   * *Learning Objective:* Students can identify ethical dilemmas (e.g., the trolley problem in autonomous vehicles) and propose regulatory solutions.  
3. **AI Techniques and Applications:**  
   * *Concept:* Foundational knowledge (Machine Learning, Neural Networks).  
   * *Key Competency:* "AI Foundations."  
   * *Learning Objective:* Students can explain the difference between rule-based systems and machine learning. They understand data training, validation, and testing.  
4. **AI System Design:**  
   * *Concept:* Problem-solving and design thinking.  
   * *Key Competency:* "Problem solving with AI."  
   * *Learning Objective:* Students can design a simple AI workflow to solve a community problem (e.g., identifying waste types).

#### **3.1.2 Progression Levels: The Spiral Curriculum**

UNESCO suggests a spiral curriculum moving through three levels of mastery.21 This is critical for designing coursework that caters to beginners and advanced users.

* **Level 1: Understand:** Recognizing AI in daily life, defining terms, understanding the "magic" is just math.  
* **Level 2: Apply:** Using AI tools to solve defined problems. Prompt engineering, selecting the right tool for the task.  
* **Level 3: Create:** Designing basic AI systems, co-creating with AI, or auditing systems.

Specific Curricular Goals from UNESCO 23:

* "Explain how open-source datasets and libraries... can be leveraged."  
* "Calculate the selected AI model's consumption of computing resources." (Sustainability).  
* "Exemplify locally accessible online communities of AI co-creators."

### **3.2 The Digital Education Council (DEC) Framework**

The DEC framework adds a crucial layer of "Emotional Intelligence" to the standard technical definitions.24

#### **3.2.1 The 5 Dimensions of the DEC Framework**

1. **Understanding AI and Data:** The raw fuel of AI. Users must grasp that "AI is math on data."  
2. **Critical Thinking and Judgment:** The ability to *challenge* output.  
   * *Key Skill:* **"Hallucination Detection."** Users must learn that plausibility ![][image2] truth.  
3. **Ethical and Responsible Use:** Citations, plagiarism, and intellectual property.  
4. **Human-Centricity, Emotional Intelligence, & Creativity:**  
   * *Unique Addition:* Using AI to *enhance* human empathy rather than replace it. Understanding that AI cannot replicate genuine human connection.  
5. **Domain Expertise:** Applying AI to specific contexts (Law, Art, Engineering).

### **3.3 Synthesis: The "AI Citizen" Profile**

Combining these frameworks, we can define the "Literate AI Citizen" as someone who:

1. **Identifies** AI systems in their environment (Transparency).  
2. **Understand** the data-driven, probabilistic nature of these systems (Technological Dimension).  
3. **Evaluates** outputs for bias, accuracy, and manipulation (Critical Thinking).  
4. **Operates** tools effectively for personal/professional goals (Practical Dimension).  
5. **Participates** in democratic oversight and governance (Human Dimension).

## ---

**4\. Risk Management as a Civic Skill (The "How")**

For the general population, "AI Safety" is often abstract. However, institutional standards provide concrete methodologies for managing risk. The curriculum must translate these corporate/governmental frameworks into personal safety habits.

### **4.1 NIST AI Risk Management Framework (AI RMF 1.0)**

The **NIST AI RMF** is the gold standard for managing AI risk in the United States and is widely respected globally.7 While written for organizations, its core functions—**Map, Measure, Manage, Govern**—provide an excellent heuristic for teaching citizens how to approach AI safety.8

#### **4.1.1 Translating NIST for the Public: The "Personal RMF"**

* **MAP (Context):**  
  * *Standard:* Establish context and intended use.  
  * *Citizen Lesson:* "Context Matters." An AI writing a poem has low risk; an AI writing a medical prescription has high risk.  
  * *Activity:* "Risk Mapping." Users are given a list of AI tools (Siri, ChatGPT, Resume Screener) and must map them on a "Harm Matrix."  
* **MEASURE (Analysis):**  
  * *Standard:* Assess and track risks (bias, reliability).  
  * *Citizen Lesson:* "Trust but Verify." Teach users to measure the accuracy of an AI by cross-referencing with trusted sources.  
  * *Activity:* "The Fact-Checker." Users are given a plausible but false AI-generated article and must find the errors.  
* **MANAGE (Mitigation):**  
  * *Standard:* Prioritize and act on risks.  
  * *Citizen Lesson:* "Safe Usage Protocols." Never input PII (Personally Identifiable Information) into a public LLM. Use settings to opt-out of data training.  
  * *Activity:* "Privacy Settings Audit." A walkthrough of finding and changing data settings in popular AI tools.  
* **GOVERN (Culture):**  
  * *Standard:* Policies and procedures.  
  * *Citizen Lesson:* "Civic Governance." Advocating for laws that require labeling of AI content.  
  * *Activity:* "Town Hall." A simulation where users debate a proposed local ordinance on facial recognition.

### **4.2 ISO/IEC 42001: The Management System Standard**

ISO 42001 is the international standard for AI Management Systems.28 It emphasizes **Continuous Improvement** and **Stakeholder Engagement**.

* **Key Concept:** AI is not "set and forget." It drifts.  
* **Curriculum Insight:** Public education should teach that AI performance degrades or changes over time as data changes. This counters the "static appliance" mental model (e.g., a toaster works the same way forever; an AI does not).  
* **Activity:** "The Drifting Bot." A simulation where an AI starts helpful but becomes biased over time due to bad user data, teaching the concept of *model drift* and the need for constant monitoring (ISO's "Continual Improvement").

### **4.3 The EU AI Act: Legal Literacy and Risk Tiers**

The **EU AI Act** is the first comprehensive AI law.31 Article 4 explicitly mandates "AI Literacy."

* **Key Definition (Article 3(56)):** Literacy is the skills/knowledge to make an *informed deployment* and gain awareness of *opportunities and risks*.2  
* **Risk Tiers:** The Act categorizes AI into "Unacceptable," "High," "Limited," and "Minimal" risk.  
  * **Unacceptable Risk:** Social scoring, biometric manipulation. (Banned).  
  * **High Risk:** Critical infrastructure, education, employment, law enforcement. (Strictly regulated).  
  * **Limited Risk:** Chatbots, emotion recognition systems. (Transparency obligations).  
  * **Minimal Risk:** Spam filters, video games. (No restrictions).  
* **Curriculum Must-Have:** A module where users categorize different AIs. This demystifies regulation and helps citizens understand which tools require caution.

### **4.4 Mozilla Trustworthy AI: Consumer Protection**

Mozilla focuses on the consumer/citizen perspective, emphasizing **privacy**, **open source**, and **corporate accountability**.33

* **Key Insight:** "Privacy Not Included." Mozilla’s guide reviews gadgets and apps for privacy safety.  
* **Curriculum Application:** Teach users to read "Privacy Labels" or Terms of Service summaries. Use Mozilla's "Data Futures" concepts to discuss data trusts and cooperatives.35

## ---

**5\. National Strategies – Case Studies in Implementation**

Analyzing how different nations implement these standards offers distinct templates for public coursework. The curriculum can draw specific "modules" from these national experiments.

### **5.1 Finland: The "Elements of AI" Model (Civic Empowerment)**

Finland’s goal was to educate 1% of its population on AI fundamentals. They exceeded this, reaching millions globally.

* **Core Philosophy:** AI is not magic; it is math. The course is text-heavy, philosophical, and math-lite but conceptually deep.5  
* **Syllabus Highlights:**  
  1. **What is AI?** (Philosophy of intelligence, Turing test).  
  2. **Problem Solving** (Search algorithms, games, min-max algorithm).  
  3. **Real World AI** (Bayes' theorem, probability, odds).  
  4. **Machine Learning** (Linear regression, supervised vs unsupervised).  
  5. **Neural Networks** (Perceptrons, backpropagation explained simply).  
  6. **Implications** (Societal impact, bias).  
* **Takeaway for Coursework:** Do not underestimate the public. The "Elements of AI" success proves that people *want* to understand the logic (Bayes' theorem), not just the application. Interactive coursework should include "Math for Non-Mathematicians" modules to explain *probability*.

### **5.2 Singapore: "AI for Everyone" (Economic Pragmatism)**

Singapore’s approach is shorter (3-5 hours) and focused on **identifying use cases** and **Smart Nation** goals.37

* **Target:** Non-technical laypeople and business professionals.  
* **Structure:**  
  * *Awareness:* What can AI do vs. what it cannot.  
  * *Play:* Hands-on with tools (Azure, Google, or local equivalents).  
  * *Identify:* Spotting opportunities in one's own job or community.  
* **Unique Feature:** "Smart Nation" integration. The coursework ties AI literacy directly to national survival and economic competitiveness.  
* **Pedagogical Insight:** Use local, relatable examples (e.g., how AI routes local buses or processes local taxes) to increase engagement.

### **5.3 Philippines: The "Workforce Transformation" Model**

The Philippines leverages AI education for economic leapfrogging, specifically in the Business Process Outsourcing (BPO) sector.41

* **SPARTA Project:** "Smarter Philippines through Data Analytics R\&D, Training, and Adoption."  
* **Pathways:** Defined roles like **Data Associate** (entry-level, analyzes data) and **Data Steward** (governance, gatekeeper of data quality).45  
* **Strategic Alignment:** The **National AI Strategy Roadmap (NAISR) 2.0** focuses on "upskilling and reskilling" to prevent displacement.43  
* **Coursework Implication:** For developing economies or workforce-focused modules, literacy is tied to *employability*. Coursework should emphasize "AI-augmented" workflows (e.g., "How to use AI to improve customer service speed") rather than abstract theory. The concept of "Data Stewardship" is a valuable addition to general literacy—teaching people to care for data quality.

### **5.4 The United Kingdom: Safe and Effective Use**

The UK’s "AI Playbook" and "Generative AI Framework" focus on public sector safety and efficiency.47

* **Key Theme:** "Safe, Responsible, Effective."  
* **Guidance:** Concrete checklists for data privacy and intellectual property before using tools.  
* **Insight:** The UK emphasizes "Intellectual Property" and "Copyright" risks heavily. This is a crucial literacy component for creators.

## ---

**6\. Pedagogical Architectures for Interactive Learning**

Based on the **Digital Education Council**, **UNESCO**, and **Digital Promise** frameworks, this section outlines the pedagogical architecture for the proposed coursework.

### **6.1 Andragogy for the Algorithmic Age**

Adult learning (andragogy) requires relevance, problem-orientation, and self-direction. The **Council of Europe** and **DEC** findings suggest moving beyond "lectures" to "engagement modes".49

#### **6.1.1 The "Understand \- Evaluate \- Use" Loop**

Digital Promise’s framework offers a robust cycle for interactive activities 49:

1. **Understand (Cognitive):** Interactive diagrams of Neural Networks (e.g., "The neuron fires when..."). Use visual metaphors (e.g., AI as a parrot mimicking speech).  
2. **Evaluate (Critical):** Exercises where users must "grade" AI outputs for accuracy and bias. This shifts the user from consumer to critic.  
3. **Use (Functional):** Sandbox environments where users prompt an AI to solve a riddle or draft an email, then refine the prompt.

#### **6.1.2 Gamification of Ethics**

Sources highlight the success of "Gamified Cheating" (e.g., *Goblinly*) to teach ethics.50

* **Concept:** Allow users to try to "trick" an AI or use it unethically in a safe simulation.  
* **Learning Moment:** When the AI fails or produces harmful content in the game, the user learns the *consequence* without real-world harm.  
* **Activity:** "The Bias Hunter." Players race to find prompts that reveal bias in a simulated model. The more bias they find, the higher their score. This teaches them *how* models fail.

### **6.2 Proposed Curriculum Modules (Syllabus)**

Based on the synthesized standards, here is a proposed syllabus for a 15-hour comprehensive course.

#### **Module 1: The Mechanical Mind (Technological Literacy)**

* **Source:** UNESCO "AI Techniques" / Finland "Elements of AI".  
* **Topics:** Algorithms, Data, Probability, Machine Learning vs. Rule-based.  
* **Interactive:** **"Train Your Dragon."** A simple Teachable Machine interface where users classify images (cats vs. dogs) and see how "bad data" (e.g., only black cats) leads to "bad predictions."  
* **Key Takeaway:** "AI is opinion solidified in math."

#### **Module 2: The Critical Eye (Safety & Evaluation)**

* **Source:** NIST "Measure" / EU "Robustness".  
* **Topics:** Hallucinations, Confidence Intervals, Deepfakes, Adversarial Attacks.  
* **Interactive:** **"Spot the Fake."** Users are presented with 5 emails/images; 3 are AI-generated, 2 are human. They must identify artifacts (extra fingers, weird phrasing).  
* **Deep Dive:** Understanding **Probabilistic vs. Deterministic.** "The AI doesn't *know* the answer; it guesses the next word."

#### **Module 3: The Data Self (Privacy & Rights)**

* **Source:** CoE "Human Dimension" / EU "Privacy".  
* **Topics:** Data Harvesting, Inference, Surveillance, GDPR/Privacy Laws.  
* **Interactive:** **"The Data Mirror."** A visualization tool (simulated) showing what an AI *infers* about the user based on 5 clicks (e.g., "You are likely male, 30s, anxious").  
* **Goal:** Visceral understanding of inference risks.

#### **Module 4: The Human-in-Command (Agency & Ethics)**

* **Source:** OECD "Human-Centred Values" / EU "Agency".  
* **Topics:** Automation Bias, Accountability, Ethical Decision Making.  
* **Interactive:** **"The Cockpit."** A simulation of a high-stakes decision (e.g., approving a loan). The AI recommends "Reject" based on a biased correlation (zip code). The user must find the error and *override* the AI.  
* **Victory Condition:** Successfully disagreeing with the AI when it is wrong.

#### **Module 5: Future of Work & Society (Societal Well-being)**

* **Source:** UNESCO "Human-centred mindset" / Philippines NAISR.  
* **Topics:** Co-creation, Augmentation vs. Replacement, Economic Impact.  
* **Interactive:** **"The Centaur."** A collaborative task where the user and AI take turns to write a story or solve a puzzle. The goal is to produce a result better than either could alone.

### **6.3 Assessment Standards**

How do we certify "AI Literacy"?

* **Avoid:** Multiple choice questions on definitions (e.g., "What is a neural network?").  
* **Adopt:** Scenario-based assessment.51  
  * *Example:* "You are a teacher. A student submits this essay. Use these three AI detection strategies to determine if it is original."  
  * *Metric:* Success is measured by the *process* of verification (checking metadata, using tools, critical reading), not just the final answer.  
  * *Validation:* Research shows that objective-based assessments (solving a problem) are more valid for AI literacy than self-reported confidence.51

## ---

**7\. Deep Dive into Specific Safety Standards for Coursework**

This section elaborates on specific safety concepts that must be translated for the public, referencing the **Mozilla Trustworthy AI** and **AI Safety Awareness** curriculum.33

### **7.1 Epistemic Safety (Protecting Truth)**

The OECD and UK government emphasize the risk of **misinformation** amplified by AI.15

* **Curriculum Requirement:** Users must learn "Provenance."  
* **Technique:** "Lateral Reading." Teach users to leave the content and check the source, rather than analyzing the content itself (which AI makes convincing).  
* **Concept:** "Information Integrity." Understanding that AI can generate infinite content, so the *cost* of generating lies has dropped to zero.

### **7.2 Psychological Safety (Anthropomorphism)**

The **Council of Europe** warns against the "anthropomorphic qualities" of generative AI leading to emotional manipulation.9

* **Standard:** AI systems must be identifiable as such (EU AI Act Transparency Requirement).3  
* **Lesson:** "It's a Tool, Not a Friend." Analyze the language AI uses ("I'm sorry," "I think"). Discuss why this is programmed politeness, not empathy.  
* **Risk:** Vulnerable populations (children, elderly) forming "parasocial relationships" with bots. Coursework must address this psychological vulnerability.

### **7.3 Fairness and Bias Mitigation**

NIST’s "Fairness" pillar requires identifying systemic bias.8

* **Interactive Demo:** Show how "predictive policing" algorithms can create feedback loops (police go where crime is predicted ![][image1] arrest more people there ![][image1] data says more crime is there ![][image1] loop).  
* **Source Material:** Use the "Datasheets for Datasets" concept (Mitchell et al., often cited in ethical frameworks) to teach users to ask: "What data trained this?"

### **7.4 Security and Robustness**

The **EU HLEG** emphasizes resilience to attack.3

* **For the Public:** This means "Cyber Hygiene."  
* **Lesson:** Phishing 2.0. AI can write perfect phishing emails (no typos, perfect context). Users must learn new detection methods (verifying channels, not just content).

## ---

**8\. Recommendations for Implementation**

Based on the synthesis of these global standards, the following recommendations are made for the development of interactive coursework.

### **8.1 Embrace "Safe Failure"**

Learning environments should be sandboxes where users can safely experience the negative consequences of poor AI use. Let them accidentally "leak" data in a game, or "break" a model. This experiential learning is supported by the **NIST Manage** function.7

### **8.2 Localize the Context**

Following the **Philippines** and **Singapore** examples, abstract global standards must be grounded in local economic and cultural reality. In a developing nation, focus on AI for *economic empowerment* and *access*. In the EU, focus on *rights* and *GDPR compliance*.38 The coursework should be modular to allow for this localization.

### **8.3 Prioritize "Human-in-Command"**

The ultimate goal of AI literacy is not to create better users, but to create better **commanders** of technology. Every module should reinforce the principle that the human is the moral and legal agent responsible for the AI's output (OECD Principle 1.5 Accountability).12

### **8.4 Continuous Updates (The Living Curriculum)**

Just as **NIST AI RMF** and **UNESCO** frameworks are "living documents" 18, the coursework must be dynamic. A static course will be obsolete in 6 months. Build a "Core" (Ethics, Logic) and "Extensions" (Current Tools) architecture. The "Core" remains stable; the "Extensions" (e.g., "How to use GPT-5") update regularly.

## ---

**Conclusion**

The transition to an AI-literate society is a monumental undertaking comparable to the introduction of mass public education in the industrial era. The standards provided by **UNESCO, OECD, the EU, and NIST** provide a robust, consistent, and human-centric scaffold for this education. They move us beyond the superficial "coding for all" mentality toward a deeper, more resilient form of citizenship.

By focusing on **Agency, Robustness, and Critical Evaluation**, rather than mere technical proficiency, we can develop coursework that empowers the general population. The goal is to graduate citizens who look at Artificial Intelligence and see neither a magical savior nor a terminating monster, but a powerful, probabilistic tool that requires a steady, ethical human hand at the helm. This report serves as the comprehensive evidence base for constructing that educational future.

### ---

**Table 1: Comparative Analysis of Key Global AI Literacy Frameworks**

| Institution | Framework Name | Key Philosophy | Core Dimensions/Pillars | Target Audience |
| :---- | :---- | :---- | :---- | :---- |
| **UNESCO** | AI Competency Frameworks 1 | Human-Centred Mindset, Global South Inclusion | 1\. Human-Centred Mindset 2\. Ethics of AI 3\. AI Techniques 4\. AI System Design | Students & Teachers |
| **OECD** | AI Principles 10 | Value-Based, Economic Well-being | 1\. Inclusive Growth 2\. Human-Centred Values 3\. Transparency 4\. Robustness 5\. Accountability | Policymakers & General Public |
| **Council of Europe** | AI Literacy Framework 9 | Human Rights, Democracy, Rule of Law | 1\. Technological Dimension 2\. Practical Dimension 3\. Human Dimension | Citizens of Democracies |
| **EU HLEG** | Ethics Guidelines for Trustworthy AI 3 | "Trustworthy AI" through Rights & Safety | 7 Requirements (Agency, Safety, Privacy, Transparency, Fairness, Well-being, Accountability) | Developers & Deployers (Public) |
| **NIST (USA)** | AI Risk Management Framework (RMF) 7 | Risk Management Lifecycle | Functions: Map, Measure, Manage, Govern Characteristics: Valid, Reliable, Safe, Secure, Resilient | Organizations (adaptable for users) |
| **Digital Education Council** | DEC AI Literacy Framework 24 | Holistic & Emotional Intelligence | 1\. Understanding Data 2\. Critical Thinking 3\. Ethics 4\. Human-Centricity/EI 5\. Domain Expertise | Higher Ed & General Public |

### **Table 2: Translating Standards into Learning Objectives for Interactive Coursework**

| Standard Source | Complex Concept | Simplified Concept for Public | Proposed Interactive Activity |
| :---- | :---- | :---- | :---- |
| **OECD Principle 1.2** | Human-Centred Values & Fairness | "You are the Boss" | Simulation: Override an AI's biased loan decision. |
| **EU AI Act Art. 5** | Subconscious Manipulation (Prohibited) | "Don't get Nudged" | Game: Spot the "Dark Pattern" in a social media feed. |
| **NIST RMF (Map)** | Contextual Risk Assessment | "High Stakes vs. Low Stakes" | Drag-and-drop: Sort AI use cases (e.g., Cancer Diagnosis vs. Song Recommendation) by risk level. |
| **UNESCO (Ethics)** | Algorithmic Bias | "Garbage In, Garbage Out" | Training Lab: Train a classifier with biased data and watch it fail, then fix the dataset. |
| **CoE (Human Dim.)** | Anthropomorphism Risks | "The Robot is Not Your Friend" | Chat Analysis: Highlight manipulative emotional language in chatbot responses. |
| **ISO 42001** | Continuous Improvement/Monitoring | "Model Drift" | Time-lapse Sim: Manage an AI system over "5 years" as it slowly degrades without human updates. |

### **Table 3: Summary of National AI Education Strategies**

| Country | Flagship Program | Primary Focus | Key Insight for Coursework |
| :---- | :---- | :---- | :---- |
| **Finland** | Elements of AI 5 | Civic Engagement, Democracy | Don't dumb it down. Teach the logic/math simply. |
| **Singapore** | AI for Everyone 37 | Economic Competitiveness, Smart Nation | Focus on *identifying* AI opportunities in daily life/work. |
| **Philippines** | SPARTA / NAISR 2.0 41 | Workforce Transition (BPO), Upskilling | Link literacy to employability and career pathways. |
| **United Kingdom** | AI Playbook 47 | Public Sector Safety, Effective Use | Use checklists and frameworks for safe deployment. |

---

*Note: This report utilizes data sourced from credible institutions including UNESCO, OECD, NIST, the European Union, and the Council of Europe, current as of early 2026\. Citations refer to the specific research snippets provided.*

#### **Works cited**

1. The AI competency frameworks for teachers and students \- UNESCO-ICHEI, accessed February 4, 2026, [https://en.ichei.org/en/news/information/924.html](https://en.ichei.org/en/news/information/924.html)  
2. Understanding AI literacy \- IAPP, accessed February 4, 2026, [https://iapp.org/news/a/understanding-ai-literacy](https://iapp.org/news/a/understanding-ai-literacy)  
3. Requirements of Trustworthy AI | FUTURIUM | European Commission, accessed February 4, 2026, [https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines/1.html](https://ec.europa.eu/futurium/en/ai-alliance-consultation/guidelines/1.html)  
4. Online safety activities and resources for Safer Internet Day | Microsoft Education Blog, accessed February 4, 2026, [https://www.microsoft.com/en-us/education/blog/2025/02/leading-the-way-to-a-safer-internet-together/](https://www.microsoft.com/en-us/education/blog/2025/02/leading-the-way-to-a-safer-internet-together/)  
5. Free Course: Elements of AI from University of Helsinki | Class Central, accessed February 4, 2026, [https://www.classcentral.com/course/independent-elements-of-ai-12469](https://www.classcentral.com/course/independent-elements-of-ai-12469)  
6. Elements of AI | AI Campus, accessed February 4, 2026, [https://ki-campus.org/en/learning-opportunities/courses/elements-ai](https://ki-campus.org/en/learning-opportunities/courses/elements-ai)  
7. Safeguard the Future of AI: The Core Functions of the NIST AI RMF \- AuditBoard, accessed February 4, 2026, [https://auditboard.com/blog/nist-ai-rmf](https://auditboard.com/blog/nist-ai-rmf)  
8. NIST AI Risk Management Framework: A simple guide to smarter AI ..., accessed February 4, 2026, [https://www.diligent.com/resources/blog/nist-ai-risk-management-framework](https://www.diligent.com/resources/blog/nist-ai-risk-management-framework)  
9. A three-dimensional AI literacy framework \- https: //rm. coe. int \- The ..., accessed February 4, 2026, [https://rm.coe.int/policy-brief-16/1680b69437](https://rm.coe.int/policy-brief-16/1680b69437)  
10. AI principles \- OECD, accessed February 4, 2026, [https://www.oecd.org/en/topics/ai-principles.html](https://www.oecd.org/en/topics/ai-principles.html)  
11. OECD AI Principles overview, accessed February 4, 2026, [https://oecd.ai/en/ai-principles](https://oecd.ai/en/ai-principles)  
12. Recommendation of the Council on Artificial Intelligence \- OECD Legal Instruments, accessed February 4, 2026, [https://legalinstruments.oecd.org/en/instruments/oecd-legal-0449](https://legalinstruments.oecd.org/en/instruments/oecd-legal-0449)  
13. accessed February 4, 2026, [https://verifywise.ai/lexicon/human-centric-ai-principles\#:\~:text=Human%2Dcentric%20AI%20principles%20are,design%20to%20deployment%20and%20beyond.](https://verifywise.ai/lexicon/human-centric-ai-principles#:~:text=Human%2Dcentric%20AI%20principles%20are,design%20to%20deployment%20and%20beyond.)  
14. Human-centric AI principles \- AI Governance Lexicon | VerifyWise, accessed February 4, 2026, [https://verifywise.ai/lexicon/human-centric-ai-principles](https://verifywise.ai/lexicon/human-centric-ai-principles)  
15. Human-centred values and fairness (OECD AI Principle), accessed February 4, 2026, [https://oecd.ai/en/dashboards/ai-principles/P6](https://oecd.ai/en/dashboards/ai-principles/P6)  
16. OECD Recommendation on AI \- FSMB, accessed February 4, 2026, [https://www.fsmb.org/siteassets/artificial-intelligence/pdfs/oecd-recommendation-on-ai-en.pdf](https://www.fsmb.org/siteassets/artificial-intelligence/pdfs/oecd-recommendation-on-ai-en.pdf)  
17. Ethics guidelines for trustworthy AI | Shaping Europe's digital future \- European Union, accessed February 4, 2026, [https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai](https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai)  
18. AI competency framework for students \- UNESCO, accessed February 4, 2026, [https://www.unesco.org/en/articles/ai-competency-framework-students](https://www.unesco.org/en/articles/ai-competency-framework-students)  
19. AI competency framework for teachers | UNESCO, accessed February 4, 2026, [https://www.unesco.org/en/articles/ai-competency-framework-teachers](https://www.unesco.org/en/articles/ai-competency-framework-teachers)  
20. What you need to know about UNESCO's new AI competency frameworks for students and teachers, accessed February 4, 2026, [https://www.unesco.org/en/articles/what-you-need-know-about-unescos-new-ai-competency-frameworks-students-and-teachers](https://www.unesco.org/en/articles/what-you-need-know-about-unescos-new-ai-competency-frameworks-students-and-teachers)  
21. AI competency framework for students, accessed February 4, 2026, [https://ju.se/download/18.53389cd2193ed80e16f93735/1737107934500/UNESCO%20AI%20competency%20for%20students.pdf](https://ju.se/download/18.53389cd2193ed80e16f93735/1737107934500/UNESCO%20AI%20competency%20for%20students.pdf)  
22. UNESCO AI Competency Framework For Students | PDF | Artificial Intelligence \- Scribd, accessed February 4, 2026, [https://www.scribd.com/document/868735774/UNESCO-AI-competency-framework-for-students](https://www.scribd.com/document/868735774/UNESCO-AI-competency-framework-for-students)  
23. AI competency framework for students \- UNESCO Digital Library, accessed February 4, 2026, [https://unesdoc.unesco.org/ark:/48223/pf0000391105](https://unesdoc.unesco.org/ark:/48223/pf0000391105)  
24. Digital Education Council AI Literacy Framework, accessed February 4, 2026, [https://www.digitaleducationcouncil.com/post/digital-education-council-ai-literacy-framework](https://www.digitaleducationcouncil.com/post/digital-education-council-ai-literacy-framework)  
25. 5 essential dimensions of AI literacy \- eCampus News, accessed February 4, 2026, [https://www.ecampusnews.com/ai-in-education/2025/12/12/5-essential-dimensions-of-ai-literacy/](https://www.ecampusnews.com/ai-in-education/2025/12/12/5-essential-dimensions-of-ai-literacy/)  
26. DEC AI Literacy Framework, accessed February 4, 2026, [https://moodle.net/.pkg/@moodlenet/ed-resource/dl/ed-resource/lei05IDJ/771\_DEC\_AI\_Literacy\_Framework.pdf](https://moodle.net/.pkg/@moodlenet/ed-resource/dl/ed-resource/lei05IDJ/771_DEC_AI_Literacy_Framework.pdf)  
27. AI Risk Management Framework | NIST \- National Institute of Standards and Technology, accessed February 4, 2026, [https://www.nist.gov/itl/ai-risk-management-framework](https://www.nist.gov/itl/ai-risk-management-framework)  
28. ISO/IEC 42001:2023 Artificial Intelligence Management System Standards \- Microsoft Learn, accessed February 4, 2026, [https://learn.microsoft.com/en-us/compliance/regulatory/offering-iso-42001](https://learn.microsoft.com/en-us/compliance/regulatory/offering-iso-42001)  
29. Understanding ISO 42001 and Demonstrating Compliance \- ISMS.online, accessed February 4, 2026, [https://www.isms.online/iso-42001/](https://www.isms.online/iso-42001/)  
30. ISO/IEC 42001: a new standard for AI governance \- KPMG International, accessed February 4, 2026, [https://kpmg.com/ch/en/insights/artificial-intelligence/iso-iec-42001.html](https://kpmg.com/ch/en/insights/artificial-intelligence/iso-iec-42001.html)  
31. AI Literacy \- Questions & Answers | Shaping Europe's digital future \- European Union, accessed February 4, 2026, [https://digital-strategy.ec.europa.eu/en/faqs/ai-literacy-questions-answers](https://digital-strategy.ec.europa.eu/en/faqs/ai-literacy-questions-answers)  
32. Article 4: AI literacy | EU Artificial Intelligence Act, accessed February 4, 2026, [https://artificialintelligenceact.eu/article/4/](https://artificialintelligenceact.eu/article/4/)  
33. Trustworthy Artificial Intelligence \- Mozilla Foundation, accessed February 4, 2026, [https://www.mozillafoundation.org/en/internet-health/trustworthy-artificial-intelligence/](https://www.mozillafoundation.org/en/internet-health/trustworthy-artificial-intelligence/)  
34. Mozilla's Approach to Trustworthy Artificial Intelligence (AI), accessed February 4, 2026, [https://www.mozillafoundation.org/en/blog/mozillas-approach-to-trustworthy-artificial-intelligence-ai/](https://www.mozillafoundation.org/en/blog/mozillas-approach-to-trustworthy-artificial-intelligence-ai/)  
35. Creating Trustworthy AI, accessed February 4, 2026, [https://assets.mofoprod.net/network/documents/Mozilla-Trustworthy\_AI.pdf](https://assets.mofoprod.net/network/documents/Mozilla-Trustworthy_AI.pdf)  
36. Elements of AI \- NTNU, accessed February 4, 2026, [https://www.ntnu.edu/ailab/elements-of-ai](https://www.ntnu.edu/ailab/elements-of-ai)  
37. AI For Everyone | Coursera, accessed February 4, 2026, [https://www.coursera.org/learn/ai-for-everyone](https://www.coursera.org/learn/ai-for-everyone)  
38. \#LEARNAI \- Learn AI (Singapore), accessed February 4, 2026, [https://learn.aisingapore.org/wp-content/uploads/2023/01/LearnAI-Booklet-2023\_v2.pdf](https://learn.aisingapore.org/wp-content/uploads/2023/01/LearnAI-Booklet-2023_v2.pdf)  
39. AI for Everyone (AI4E) \- AI Fundamentals \- AI Singapore, accessed February 4, 2026, [https://aifundamentals.aisingapore.org/lesson/ai-for-everyone-ai4e/](https://aifundamentals.aisingapore.org/lesson/ai-for-everyone-ai4e/)  
40. AI for Everyone (Multilingual Edition \- English) \- YouTube, accessed February 4, 2026, [https://www.youtube.com/watch?v=Ow1HtjKFAqo](https://www.youtube.com/watch?v=Ow1HtjKFAqo)  
41. The National Artificial Intelligence (AI) Strategy for the Philippines \- ANU Open Research, accessed February 4, 2026, [https://openresearch-repository.anu.edu.au/bitstreams/eae21503-afbe-4a26-8e9e-39c3f4905f1b/download](https://openresearch-repository.anu.edu.au/bitstreams/eae21503-afbe-4a26-8e9e-39c3f4905f1b/download)  
42. Philippines | Global AI Ethics and Governance Observatory \- UNESCO, accessed February 4, 2026, [https://www.unesco.org/ethics-ai/en/philippines](https://www.unesco.org/ethics-ai/en/philippines)  
43. Powered by AI – The Philippines' National AI Strategy Roadmap 2.0 \- Gorriceta, accessed February 4, 2026, [https://gorricetalaw.com/philippines-powered-by-ai-the-philippines-national-ai-strategy-roadmap-2-0/](https://gorricetalaw.com/philippines-powered-by-ai-the-philippines-national-ai-strategy-roadmap-2-0/)  
44. National AI Strategy Roadmap 2.0 \- July 2024 \- Erika Fille Legara, accessed February 4, 2026, [https://erikalegara.com/uploads/NAISR2.0\_July2024.pdf](https://erikalegara.com/uploads/NAISR2.0_July2024.pdf)  
45. Project SPARTA \- Development Academy of the Philippines (DAP), accessed February 4, 2026, [https://sparta.dap.edu.ph/](https://sparta.dap.edu.ph/)  
46. Smarter Philippines Through Data Analytics, R\&D, Training and Adoption (SPARTA) project through a grant provided by the Depa \- Southern Leyte State University, accessed February 4, 2026, [https://southernleytestateu.edu.ph/index.php/en/component/bdthemes\_shortcodes/?view=download\&id=b06c8419b47e68e7440f7926a4a5ae](https://southernleytestateu.edu.ph/index.php/en/component/bdthemes_shortcodes/?view=download&id=b06c8419b47e68e7440f7926a4a5ae)  
47. Launching the Artificial Intelligence Playbook for the UK Government \- GDS blog, accessed February 4, 2026, [https://gds.blog.gov.uk/2025/02/10/launching-the-artificial-intelligence-playbook-for-the-uk-government/](https://gds.blog.gov.uk/2025/02/10/launching-the-artificial-intelligence-playbook-for-the-uk-government/)  
48. Artificial Intelligence Playbook for the UK Government \- GOV.UK, accessed February 4, 2026, [https://assets.publishing.service.gov.uk/media/67aca2f7e400ae62338324bd/AI\_Playbook\_for\_the\_UK\_Government\_\_12\_02\_.pdf](https://assets.publishing.service.gov.uk/media/67aca2f7e400ae62338324bd/AI_Playbook_for_the_UK_Government__12_02_.pdf)  
49. Building AI Literacy in Adult Education: A Framework for Action \- OTAN.us, accessed February 4, 2026, [https://otan.us/StayConnected/Home/AdultEducationArticle/2142](https://otan.us/StayConnected/Home/AdultEducationArticle/2142)  
50. We gamified cheating with AI … with a little help from goblins \- Education Futures, accessed February 4, 2026, [https://educationfutures.com/post/gamifying-cheating-with-ai-building-an-ethics-of-play/](https://educationfutures.com/post/gamifying-cheating-with-ai-building-an-ethics-of-play/)  
51. Development of an AI literacy assessment for non-technical individuals: What do teachers know? \- Contemporary Educational Technology, accessed February 4, 2026, [https://www.cedtech.net/article/development-of-an-ai-literacy-assessment-for-non-technical-individuals-what-do-teachers-know-14619](https://www.cedtech.net/article/development-of-an-ai-literacy-assessment-for-non-technical-individuals-what-do-teachers-know-14619)  
52. Development of an AI literacy assessment for non-technical individuals: What do teachers know? \- ERIC, accessed February 4, 2026, [https://files.eric.ed.gov/fulltext/EJ1437452.pdf](https://files.eric.ed.gov/fulltext/EJ1437452.pdf)  
53. Content for Curriculum for the AI Safety, Ethics, and Society Course, accessed February 4, 2026, [https://www.aisafetybook.com/curriculum](https://www.aisafetybook.com/curriculum)  
54. Executive Summary \- AIRC \- NIST AI Resource Center, accessed February 4, 2026, [https://airc.nist.gov/airmf-resources/airmf/0-ai-rmf-1-0/](https://airc.nist.gov/airmf-resources/airmf/0-ai-rmf-1-0/)

[image1]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABMAAAAXCAYAAADpwXTaAAABYElEQVR4Xn1Uu04EMQxMJCRO4iEkqhMIPuL4GCpKCip6SkRJhWiuobiSH+DH6Jl1YnvsZBnJ8fjt3O5eKQGVmPOINb+BEjg31NXB5tHr0Lq6nHFbtVIoG4PpsEC6PBuheSerDTN0e6G5K+sBlCDUE5frkpX03GyeUDkrNF8ub3b2AhvkPkKf5oAkxyejBjt1I/l1FvaGY+f5rDPXRrRt76XYgb9DH5lnQehBdtayVV9LptTyDPIwTIRc4NyCblVX4aOgVGM36PgF/QE51zEnkBfIXqSWfRVem13UzlriP5BfyCvkWLrFO/WLZL9fRnEH+Yb7OgdiLr8m2qi7+vO8BD1A31rOHGOE39Wun0DuzSdEktpT8syxmcDdG8gnHFfus/8TGmuhGaiylDN2TDDvGLdm33K0jcYvkZOdTj61ETEcChyh6X881vqqTVUa0DljZXjRiD1+S0p/0eLpZxjs+g8MBBQe/kehnAAAAABJRU5ErkJggg==>

[image2]: <data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAXCAYAAADUUxW8AAABQ0lEQVR4XoVTsUqDQQxOwA7dREHo4NZNN4fiUBCkFJwF36Xo5qLgIFToiwg+Tx18AF/A73L575LL9ffjz5/kS3KXQI6YKsRWIthqVX5gnWMQTrbgTvzQQYKGD2njxB3krHg1pPNY2C6Y5vjvIFMTHIGf4xGysuGDNzejz2HjVp42fOsEMMIvpLeOp0ZcoGCLqknpzl0feikjJPWK39LlmNQTyBeYPbg9ibBq+oH8gv9GgfCa8xRurgeKdQT1Dvu60E13TjfFV1BvlA7xQQXrx3QKNYM9oyznlBdi3fCDHA/1E/xuYd5X4Q34T/APsDPHOcY5ZxFaUTe1+QG5dGxAn18i8Ex5HFECqyxvgEXAQmAxLGkLYl110gqmB5BW8h/4jPTUdiRPr/M8Bc0umKQbyKa65GcLttEFgbB1vZkDOm1bQu0/J5IdT5iyJ1gAAAAASUVORK5CYII=>