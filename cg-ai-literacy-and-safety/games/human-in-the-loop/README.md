# Human-in-the-Loop: Trust, But Verify

Learn when to trust AI recommendations and when to exercise human judgment.

## Learning Objectives

- Recognize automation bias — the tendency to over-rely on automated systems
- Develop skills for evaluating AI confidence vs actual accuracy
- Understand when human oversight is critical in AI-assisted decisions
- Learn about appropriate trust calibration across different risk domains

## Gameplay

1. **Read the Case File** — Each scenario is presented as a case file card with stakes indicator
2. **Review AI Recommendation** — See the AI system's suggestion and reasoning
3. **Investigate** — Spend tokens to reveal clues about the AI's track record and case details
4. **Decide** — ACCEPT the AI recommendation or OVERRIDE with human judgment
5. **Learn** — See the consequences, unlock AI literacy concepts, and get mentor feedback

## Framework Alignment

- **UNESCO AI Competency**: Ethics of AI, AI system design
- **OECD AI Principles**: Human-centred values, robustness/safety, accountability
- **EU Ethics Guidelines**: Human agency, robustness, transparency
