# Hallucination Hunt: Evidence Board

Fact-check AI-generated claims using limited verification tools.

## Learning Objectives

- Identify common types of AI hallucinations: fabricated citations, wrong statistics, confident nonsense, partial truths
- Develop verification skills using multiple investigation tools
- Understand the limitations of AI-generated content
- Learn to distinguish between trustworthy, hallucinated, and unverifiable claims

## Gameplay

1. **Claim Card** — An AI-generated claim is dealt as a newspaper clipping card
2. **Investigate** — Play tool cards from your hand to reveal investigation results:
   - Citation Check (blue) — verify if sources exist
   - Fact Cross-Reference (green) — compare against known facts
   - Source Verification (yellow) — check named experts/institutions
   - Logic Analysis (red) — find internal contradictions
   - Expert Consultation (purple) — get a hint
3. **Stamp Verdict** — VERIFIED, HALLUCINATED, or UNVERIFIABLE
4. **Evidence Board** — Judged claims accumulate on your board
5. **Earn Certification** — Bronze (60%), Silver (80%), Gold (90%)

## Framework Alignment

- **UNESCO AI Competency**: AI techniques, ethics of AI
- **OECD AI Principles**: Transparency, human-centred values
- **NIST AI RMF**: MEASURE (analysis), MANAGE (mitigation)
