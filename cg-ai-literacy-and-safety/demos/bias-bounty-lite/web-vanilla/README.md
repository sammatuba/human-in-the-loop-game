# Bias Bounty - Full Version

**Version:** 1.1.0  
**Status:** âœ… Production Ready (Lite â†’ Full Transformation Complete)

A collaborative investigation game about AI bias patterns, featuring UNESCO/OECD/NIST/EU framework alignment, real-world impact visualization, concept mastery assessment, and adaptive difficulty.

---

## ğŸ® Play Now

Open `index.html` in any modern web browser. No installation or internet connection required after loading.

**Recommended Browsers:** Chrome, Firefox, Safari, Edge (latest versions)

---

## What's New in v1.1 (Full Version)

### ğŸ“š Foundation Framework Alignment
Every problem now shows alignment with major AI ethics frameworks:
- **UNESCO AI Competency Framework** - Human-centred mindset, ethics, techniques
- **OECD AI Principles** - Inclusive growth, transparency, accountability
- **NIST AI Risk Management Framework** - MAP, MEASURE, MANAGE, GOVERN
- **EU Ethics Guidelines** - Human agency, fairness, well-being

### ğŸŒ Real-World Impact Visualization
See the actual consequences of AI bias:
- Statistics on affected populations
- Real-world case study references
- Cumulative impact tracking
- Examples: Amazon recruiting, Optum healthcare, Apple Card lending

### ğŸ“ Concept Mastery Assessment
Verify learning beyond pattern matching:
- Pre-game and post-game quizzes
- 8 questions covering all bias patterns
- Personalized feedback and explanations
- Visual mastery tracking per pattern type

### ğŸšï¸ Adaptive Difficulty
Choose your challenge level:
- **Beginner** (ğŸŒ±): 90s timer, hints always visible
- **Standard** (âš–ï¸): 60s timer, standard hints, 1.5x scoring
- **Expert** (ğŸ”¥): 45s timer, no hints, 2x scoring

### ğŸ’¾ Progress Persistence
Your progress is automatically saved:
- Resume where you left off
- Track scores across sessions
- View completion statistics

---

## ğŸ¯ How to Play

### The Goal
Investigate 8 real-world AI systems and identify how unfairness enters them. Match each problem to one of three bias patterns.

### The Three Patterns

| Pattern | Icon | Description | Look For |
|---------|------|-------------|----------|
| **Bad Start** | ğŸ“š | The AI learned from biased history | "trained on", "historical data", "past decisions" |
| **Wrong Measuring** | ğŸ“ | The AI measures success poorly | "optimizes for", "metric", "score" that doesn't match goal |
| **Sneaky Shortcuts** | ğŸ­ | The AI finds hidden ways to discriminate | "correlates with", "proxies", "indirect" discrimination |

### Game Phases

1. **ğŸ” Reveal System** - Learn about an AI system and its purpose
2. **âš ï¸ Reveal Problems** - See 3 specific issues with that system
3. **ğŸ¤« Observe** - Study silently (timer based on difficulty)
4. **ğŸ’¬ Discuss & Vote** - Match problems to bias patterns
5. **âœ“ Commit** - Confirm your answers
6. **ğŸ¤” Reflect** - Learn from results, frameworks, and real-world impacts

### Scoring

- Base points: 1 per correct answer
- Difficulty multipliers:
  - Beginner: 1x
  - Standard: 1.5x
  - Expert: 2x
- Perfect rounds trigger confetti celebration! ğŸ‰

---

## ğŸ—ï¸ Systems Investigated

| System | Domain | Real-World Example |
|--------|--------|-------------------|
| ğŸ’¼ Hiring Helper | Employment | Amazon AI recruiting tool bias |
| ğŸ¦ Loan Approver | Finance | Apple Card gender bias investigation |
| ğŸ¥ Health Predictor | Healthcare | Optum racial bias in care prediction |
| ğŸ“ School Sorter | Education | UK A-level algorithm controversy |
| ğŸ‘® Crime Forecaster | Criminal Justice | PredPol predictive policing bias |
| ğŸš— Insurance Rater | Finance | Auto insurance algorithm discrimination |
| ğŸ“± Content Recommender | Social Media | Facebook/Instagram mental health research |
| ğŸ¤ Voice Recognizer | Technology | Speech recognition accent bias (Stanford study) |

---

## âŒ¨ï¸ Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `â†’` or `Space` | Next Phase |
| `â†` | Previous Phase |
| `?` or `/` | Toggle Help |
| `1`, `2`, `3` | Select Pattern (during voting) |
| `Esc` | Close Modal |

---

## ğŸ“Š Educational Value

### Learning Outcomes
After playing Bias Bounty, learners will be able to:

1. **Identify** three major patterns of AI bias in real-world systems
2. **Analyze** AI systems for potential fairness issues
3. **Connect** technical AI problems to human impacts
4. **Reference** major AI ethics frameworks (UNESCO, OECD, NIST, EU)
5. **Evaluate** AI systems using structured investigation methods

### Target Audiences
- High school and university students
- AI/ML practitioners and engineers
- Policy makers and regulators
- Civic organizations and advocates
- General public interested in AI ethics

### Classroom Use
Perfect for:
- Computer science ethics courses
- AI literacy workshops
- Professional development training
- Group learning activities

---

## ğŸ”§ Technical Details

### Technology Stack
- **HTML5** - Semantic structure
- **CSS3** - Modern styling with CSS variables
- **Vanilla JavaScript** - No frameworks or dependencies
- **LocalStorage** - Progress persistence

### Browser Compatibility
- âœ… Chrome 90+
- âœ… Firefox 88+
- âœ… Safari 14+
- âœ… Edge 90+

### Performance
- Initial load: ~50KB
- Runtime memory: < 10MB
- Works offline after initial load
- Mobile responsive design

---

## ğŸ“ File Structure

```
web-vanilla/
â”œâ”€â”€ index.html      # Game structure and markup
â”œâ”€â”€ styles.css      # Complete design system (~40KB)
â”œâ”€â”€ app.js          # Game logic and data (~88KB)
â””â”€â”€ README.md       # This file
```

---

## ğŸ“ˆ Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2026-02-05 | Initial "Lite" release |
| 1.1.0 | 2026-02-06 | **Full version**: Framework alignment, impact visualization, assessment, adaptive difficulty |

---

## ğŸ“š References & Sources

The problems and examples in this game are based on documented real-world cases:

- Amazon AI recruiting tool (Reuters, 2018)
- Optum healthcare algorithm (Science, 2019)
- Apple Card gender bias (NYT, 2019)
- UK A-level algorithm (BBC, 2020)
- PredPol predictive policing (LA Times, 2021)
- Facebook internal research (WSJ, 2021)
- Speech recognition bias (Stanford study, 2020)

---

## ğŸ¤ Contributing

To modify or extend Bias Bounty:

1. Edit `app.js` to add/modify systems and problems
2. Update `styles.css` for visual changes
3. Test in multiple browsers
4. Update this README with changes

### Adding New Systems

Add to the `SYSTEMS` array:
```javascript
{
    id: 'unique-id',
    name: 'System Name',
    description: 'What it does',
    usage: 'Where it\'s used',
    goal: 'Its purpose',
    icon: 'ğŸ”§',
    category: 'domain',
    realWorldExample: 'Documented case'
}
```

Add 3 corresponding problems to the `PROBLEMS` array with framework alignment and impact data.

---

## ğŸ“„ License

This educational game is provided for non-commercial educational use.

---

## ğŸ™ Acknowledgments

Framework alignment based on:
- UNESCO Recommendation on the Ethics of AI (2021)
- OECD AI Principles (2019)
- NIST AI Risk Management Framework (2023)
- EU Ethics Guidelines for Trustworthy AI (2019)

---

**Made with â¤ï¸ for AI literacy education.**

**Play. Learn. Detect Bias.** ğŸ”
